# vim:ts=4:sw=4:expandtab

# Define a custom log format which includes the upstream latency time plus the
# contents of our own measurement data:
#
# 2001:4d88:100e:23:3a60:77ff:feab:d3ea - - [01/Oct/2012:23:03:41 +0200] "GET
# /search?q=XCreateWindow HTTP/1.1" 200 upstream 188.111.72.14:28080 response
# 0.756 request 0.756
#
log_format upstream '$remote_addr - - [$time_local] "$request" $status '
    'upstream [$upstream_addr] [$upstream_response_time]=response request $request_time';

proxy_cache_path /var/cache/nginx/cache levels=1:2
    keys_zone=main:50m
    max_size=500m inactive=15m;

proxy_temp_path /var/cache/nginx/tmp;

upstream dcsweb {
    # Keep at least 8 connections to the upstream server(s) open.
    keepalive 8;

    server localhost:28080;
}

# Set aside 10MB of RAM to store the req/s for each client IP address.
# This zone allows an average rate of 1 req/s.
limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
limit_req_zone $binary_remote_addr zone=legacy:10m rate=1r/s;

server {
    listen   80;
    listen   [::]:80 default_server ipv6only=on;

    root /usr/share/dcs/static;
    index index.html index.htm;

    server_name codesearch.debian.net;

    access_log /var/log/nginx/dcs-static.log combined;

    # 5s is a reasonably high timeout for connections, but also still low
    # enough that users might wait that long for a reply.
    proxy_connect_timeout 5s;

    # Use Keep-Alive to the upstream backend.
    proxy_http_version 1.1;
    proxy_set_header Connection "";
    proxy_set_header Host $host;

    gzip on;
    gzip_comp_level 6;
    gzip_types *;

    location /nginx_status {
        auth_basic off;
        stub_status on;
        access_log off;
        allow 127.0.0.1;
        deny all;
    }

    location = /instantws {
        limit_req zone=one burst=3 nodelay;

        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_read_timeout 3600s;
        proxy_send_timeout 3600s;

        proxy_pass http://dcsweb;
    }

    # We serve these perfectly cacheable JSON result files directly via nginx.
    location ~ ^/results/(.*)/(.*\.json)$ {
        alias /dcs-ssd/query_results/$1/$2;
        autoindex on;
        expires 1h;
    }

    location ~ ^/(perpackage-)?results/ {
        limit_req zone=one burst=3 nodelay;
        proxy_pass http://dcsweb;
    }

    # Server-rendered pages (cached and rate-limited) for legacy clients.
    location ~ ^/(search|show) {
        # Limit to 1 req/s on average.
        limit_req zone=legacy burst=3 nodelay;

        access_log /var/log/nginx/dcs-upstream.log upstream;

        proxy_read_timeout 120s;

        set $cache_key $scheme$host$uri$is_args$args$http_accept_encoding;
        proxy_cache main;
        proxy_cache_key $cache_key;
        proxy_cache_valid 15m;

        proxy_pass http://dcsweb;
    }

    # Everything else must be a static page, so we directly deliver (with
    # appropriate caching headers).
    location /research/ {
        autoindex on;
    }

    location / {
        # Cache static files for 24 hours.
        expires 24h;

        # First attempt to serve request as file, then
        # as directory, then fall back to displaying a 404.
        try_files $uri $uri.html $uri/ /index.html;
    }

    #error_page 404 /404.html;

    # redirect server error pages to the static page /50x.html
    error_page 500 502 503 504 /50x.html;
}
